apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dqa-workflow-
spec:
  entrypoint: execute-workflow

  # Use existing volume
  volumes:
  - name: workdir
    hostPath:
      path: /data/dqa-workspace
      type: Directory
    # persistentVolumeClaim:
    #   claimName: pvc-test

  arguments:
    parameters:
    - name: triplestore-url
      value: http://graphdb.dumontierlab.com/repositories/test-dqa/statements
    - name: triplestore-username
      value: import_user
    - name: triplestore-password
      value: null
    - name: graph-uri
      value: https://w3id.org/d2s/graph
    - name: rdfunit-schema
      value: null
    - name: fairsharing-metrics-url
      value: null

  templates:
  - name: execute-workflow
    steps:
    # - - name: sparql-compute-hcls-stats
    #     template: d2s-sparql-operations
    #     arguments:
    #       parameters:
    #       - name: sparql-queries-path
    #         value: "https://github.com/MaastrichtU-IDS/d2s-transform-repository/tree/master/sparql/compute-hcls-stats"
    #       - name: graph-uri
    #         value: "{{workflow.parameters.graph-uri}}"
    #       - name: triplestore-url
    #         value: "{{workflow.parameters.triplestore-url}}"
    #       - name: triplestore-username
    #         value: "{{workflow.parameters.triplestore-username}}"
    #       - name: triplestore-password
    #         value: "{{workflow.parameters.triplestore-password}}"
    - - name: run-rdfunit
        template: rdfunit
        arguments:
          parameters:
          - name: rdfunit-schema
            value: "{{workflow.parameters.rdfunit-schema}}"
    # - - name: run-fairsharing-metrics
    #     template: fairsharing-metrics
    #     arguments:
    #       parameters:
    #       - name: fairsharing-metrics-url
    #         value: "{{workflow.parameters.fairsharing-metrics-url}}"
    # - - name: upload-rdfunit
    #     template: rdf-upload
    #     arguments:
    #       parameters:
    #       - name: file-to-upload
    #         value: "/data/results"
    # - - name: upload-fairsharing-metrics
    #     template: rdf-upload
    #     arguments:
    #       parameters:
    #       - name: file-to-upload
    #         value: "/data/fairsharing.nt"

  - name: d2s-sparql-operations
    inputs:
      parameters:
      - name: sparql-queries-path
      - name: graph-uri
      - name: triplestore-url
      - name: triplestore-username
      - name: triplestore-password
    container:
      image: umids/d2s-sparql-operations:latest
      args: ["-ep", "{{inputs.parameters.triplestore-url}}", 
        "-op", "update", "-f", "{{inputs.parameters.sparql-queries-path}}",
        "-un", "{{inputs.parameters.triplestore-username}}", 
        "-pw", "{{inputs.parameters.triplestore-password}}",
        "--var-input", "{{inputs.parameters.graph-uri}}" ]

  - name: rdfunit
    inputs:
      parameters:
      - name: rdfunit-schema
    container:
      image: aksw/rdfunit:latest
      args: ["-d", "{{workflow.parameters.triplestore-url}}",
      "-f", "/data/",
      "-s", "{{inputs.parameters.rdfunit-schema}}", 
      "-o", "ttl"]
      volumeMounts:
      - name: workdir
        mountPath: /data

  - name: fairsharing-metrics
    inputs:
      parameters:
      - name: fairsharing-metrics-url
    container:
      image: umids/fairsharing-metrics:latest
      args: ["{{inputs.parameters.fairsharing-metrics-url}}"]
      volumeMounts:
      - name: workdir
        mountPath: /data
  
  - name: rdf-upload
    inputs:
      parameters:
      - name: file-to-upload
    container:
      image: umids/rdf-upload:latest
      args: ["-url", "{{workflow.parameters.triplestore-url}}",
      "-if", "{{inputs.parameters.file-to-upload}}", 
      "-un", "{{workflow.parameters.triplestore-username}}", 
      "-pw", "{{workflow.parameters.triplestore-password}}",
      "-g", "{{workflow.parameters.graph-uri}}"]
      # args: ["-url", "http://graphdb.dumontierlab.com/repositories/test-vincent/statements",
      # "-if", "/data/output/drugbank",
      # "-un", "import_user", 
      # "-pw", "test"]
      volumeMounts:
      - name: workdir
        mountPath: /data